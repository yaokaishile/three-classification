{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\p\\envs\\tensorflow\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATA_PATH = \"./data/\"\n",
    "\n",
    "def get_labels(path=DATA_PATH):\n",
    "    labels = os.listdir(path)\n",
    "    label_indices = np.arange(0, len(labels))\n",
    "    return labels, label_indices, to_categorical(label_indices)\n",
    "\n",
    "\n",
    "def wav2mfcc(file_path):\n",
    "    wave, sr = librosa.load(file_path, mono=True, sr=None)\n",
    "\n",
    "    mfcc = librosa.feature.mfcc(wave, sr=16000)\n",
    "\n",
    "    return mfcc\n",
    "\n",
    "\n",
    "def save_data_to_array(path=DATA_PATH):\n",
    "    labels, _, _ = get_labels(path)\n",
    "\n",
    "    for label in labels:\n",
    "      \n",
    "        mfcc_vectors = []\n",
    "\n",
    "        wavfiles = [path + label + '/' + wavfile for wavfile in os.listdir(path + '/' + label)]\n",
    "        for wavfile in tqdm(wavfiles, \"Saving vectors of label - '{}'\".format(label)):\n",
    "            mfcc = wav2mfcc(wavfile)\n",
    "            mfcc_vectors.append(mfcc)\n",
    "        np.save(label + '.npy', mfcc_vectors)\n",
    "\n",
    "\n",
    "def get_train_test(split_ratio=0.6, random_state=42):\n",
    "   \n",
    "    labels, indices, _ = get_labels(DATA_PATH)\n",
    "\n",
    "    \n",
    "    X = np.load(labels[0] + '.npy')\n",
    "    y = np.zeros(X.shape[0])\n",
    "\n",
    "    \n",
    "    for i, label in enumerate(labels[1:]):\n",
    "        x = np.load(label + '.npy')\n",
    "        X = np.vstack((X, x))\n",
    "        y = np.append(y, np.full(x.shape[0], fill_value= (i + 1)))\n",
    "\n",
    "    assert X.shape[0] == len(y)\n",
    "\n",
    "    return train_test_split(X, y, test_size= (1 - split_ratio), random_state=random_state, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "def prepare_dataset(path=DATA_PATH):\n",
    "    labels, _, _ = get_labels(path)\n",
    "    data = {}\n",
    "    for label in labels:\n",
    "        data[label] = {}\n",
    "        data[label]['path'] = [path  + label + '/' + wavfile for wavfile in os.listdir(path + '/' + label)]\n",
    "\n",
    "        vectors = []\n",
    "\n",
    "        for wavfile in data[label]['path']:\n",
    "            wave, sr = librosa.load(wavfile, mono=True, sr=None)\n",
    " \n",
    "           \n",
    "            mfcc = librosa.feature.mfcc(wave, sr=16000)\n",
    "            vectors.append(mfcc)\n",
    "\n",
    "        data[label]['mfcc'] = vectors\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_dataset(path=DATA_PATH):\n",
    "    data = prepare_dataset(path)\n",
    "\n",
    "    dataset = []\n",
    "\n",
    "    for key in data:\n",
    "        for mfcc in data[key]['mfcc']:\n",
    "            dataset.append((key, mfcc))\n",
    "\n",
    "    return dataset[:100]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors of label - 'bed': 100%|████████████████████████████████████████████| 1713/1713 [00:08<00:00, 197.56it/s]\n",
      "Saving vectors of label - 'cat': 100%|████████████████████████████████████████████| 1733/1733 [00:08<00:00, 204.33it/s]\n",
      "Saving vectors of label - 'happy': 100%|██████████████████████████████████████████| 1742/1742 [00:08<00:00, 199.05it/s]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "#自动加载模块\n",
    "%autoreload 2\n",
    "#%aimport每次执行键入的Python代码之前，每次重新加载所有模块（排除的除外）。\n",
    "\n",
    "from preprocess import *\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "feature_dim_2 = 32\n",
    "\n",
    "\n",
    "save_data_to_array(max_len=feature_dim_2)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_train_test()\n",
    "\n",
    "\n",
    "feature_dim_1 = 20\n",
    "channel = 1\n",
    "epochs = 50\n",
    "batch_size = 100\n",
    "verbose = 1\n",
    "num_classes = 3\n",
    "\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "X_test = X_test.reshape(X_test.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "\n",
    "y_train_hot = to_categorical(y_train)\n",
    "y_test_hot = to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', input_shape=(feature_dim_1, feature_dim_2, channel)))\n",
    "    model.add(Conv2D(48, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(Conv2D(120, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3112 samples, validate on 2076 samples\n",
      "Epoch 1/50\n",
      "3112/3112 [==============================] - ETA: 33s - loss: 2.0418 - acc: 0.40 - ETA: 10s - loss: 3.5186 - acc: 0.36 - ETA: 6s - loss: 2.8278 - acc: 0.3660 - ETA: 4s - loss: 2.3482 - acc: 0.392 - ETA: 3s - loss: 2.0831 - acc: 0.400 - ETA: 2s - loss: 1.9213 - acc: 0.400 - ETA: 1s - loss: 1.7914 - acc: 0.407 - ETA: 1s - loss: 1.6892 - acc: 0.414 - ETA: 1s - loss: 1.6096 - acc: 0.418 - ETA: 1s - loss: 1.5504 - acc: 0.423 - ETA: 0s - loss: 1.4943 - acc: 0.430 - ETA: 0s - loss: 1.4493 - acc: 0.437 - ETA: 0s - loss: 1.4141 - acc: 0.439 - ETA: 0s - loss: 1.3750 - acc: 0.449 - ETA: 0s - loss: 1.3451 - acc: 0.455 - ETA: 0s - loss: 1.3163 - acc: 0.462 - 2s 743us/step - loss: 1.3152 - acc: 0.4621 - val_loss: 1.1753 - val_acc: 0.3642\n",
      "Epoch 2/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 1.2440 - acc: 0.420 - ETA: 0s - loss: 0.9809 - acc: 0.546 - ETA: 0s - loss: 0.9190 - acc: 0.596 - ETA: 0s - loss: 0.8915 - acc: 0.612 - ETA: 0s - loss: 0.8784 - acc: 0.618 - ETA: 0s - loss: 0.8486 - acc: 0.630 - ETA: 0s - loss: 0.8064 - acc: 0.651 - ETA: 0s - loss: 0.7810 - acc: 0.669 - ETA: 0s - loss: 0.7692 - acc: 0.674 - ETA: 0s - loss: 0.7729 - acc: 0.673 - ETA: 0s - loss: 0.7579 - acc: 0.683 - ETA: 0s - loss: 0.7434 - acc: 0.689 - ETA: 0s - loss: 0.7292 - acc: 0.697 - ETA: 0s - loss: 0.7147 - acc: 0.702 - ETA: 0s - loss: 0.7101 - acc: 0.704 - ETA: 0s - loss: 0.7096 - acc: 0.705 - ETA: 0s - loss: 0.6987 - acc: 0.709 - 1s 399us/step - loss: 0.6995 - acc: 0.7092 - val_loss: 0.5656 - val_acc: 0.7823\n",
      "Epoch 3/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.7780 - acc: 0.710 - ETA: 0s - loss: 0.5961 - acc: 0.766 - ETA: 0s - loss: 0.5746 - acc: 0.778 - ETA: 0s - loss: 0.5577 - acc: 0.785 - ETA: 0s - loss: 0.5552 - acc: 0.783 - ETA: 0s - loss: 0.5743 - acc: 0.781 - ETA: 0s - loss: 0.5559 - acc: 0.789 - ETA: 0s - loss: 0.5423 - acc: 0.794 - ETA: 0s - loss: 0.5403 - acc: 0.792 - ETA: 0s - loss: 0.5456 - acc: 0.786 - ETA: 0s - loss: 0.5370 - acc: 0.791 - ETA: 0s - loss: 0.5236 - acc: 0.796 - ETA: 0s - loss: 0.5160 - acc: 0.801 - ETA: 0s - loss: 0.5089 - acc: 0.803 - 1s 310us/step - loss: 0.5087 - acc: 0.8033 - val_loss: 0.6091 - val_acc: 0.7563\n",
      "Epoch 4/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.7024 - acc: 0.730 - ETA: 0s - loss: 0.4731 - acc: 0.835 - ETA: 0s - loss: 0.4754 - acc: 0.823 - ETA: 0s - loss: 0.4627 - acc: 0.831 - ETA: 0s - loss: 0.4314 - acc: 0.842 - ETA: 0s - loss: 0.4166 - acc: 0.846 - ETA: 0s - loss: 0.4120 - acc: 0.852 - ETA: 0s - loss: 0.4105 - acc: 0.853 - ETA: 0s - loss: 0.4088 - acc: 0.853 - ETA: 0s - loss: 0.4018 - acc: 0.856 - ETA: 0s - loss: 0.4043 - acc: 0.856 - ETA: 0s - loss: 0.4016 - acc: 0.856 - ETA: 0s - loss: 0.3990 - acc: 0.858 - 1s 298us/step - loss: 0.3933 - acc: 0.8609 - val_loss: 0.3804 - val_acc: 0.8632\n",
      "Epoch 5/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.4643 - acc: 0.750 - ETA: 0s - loss: 0.4206 - acc: 0.807 - ETA: 0s - loss: 0.3829 - acc: 0.833 - ETA: 0s - loss: 0.3830 - acc: 0.836 - ETA: 0s - loss: 0.3684 - acc: 0.847 - ETA: 0s - loss: 0.3595 - acc: 0.852 - ETA: 0s - loss: 0.3589 - acc: 0.857 - ETA: 0s - loss: 0.3479 - acc: 0.863 - ETA: 0s - loss: 0.3361 - acc: 0.868 - ETA: 0s - loss: 0.3365 - acc: 0.872 - ETA: 0s - loss: 0.3351 - acc: 0.872 - ETA: 0s - loss: 0.3278 - acc: 0.875 - ETA: 0s - loss: 0.3261 - acc: 0.878 - ETA: 0s - loss: 0.3300 - acc: 0.879 - 1s 302us/step - loss: 0.3308 - acc: 0.8811 - val_loss: 0.2538 - val_acc: 0.9109\n",
      "Epoch 6/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.2294 - acc: 0.930 - ETA: 0s - loss: 0.2639 - acc: 0.902 - ETA: 0s - loss: 0.2665 - acc: 0.902 - ETA: 0s - loss: 0.2873 - acc: 0.899 - ETA: 0s - loss: 0.2835 - acc: 0.901 - ETA: 0s - loss: 0.2704 - acc: 0.906 - ETA: 0s - loss: 0.2628 - acc: 0.910 - ETA: 0s - loss: 0.2727 - acc: 0.904 - ETA: 0s - loss: 0.2652 - acc: 0.908 - ETA: 0s - loss: 0.2672 - acc: 0.908 - ETA: 0s - loss: 0.2693 - acc: 0.909 - ETA: 0s - loss: 0.2652 - acc: 0.909 - 1s 296us/step - loss: 0.2632 - acc: 0.9097 - val_loss: 0.2499 - val_acc: 0.9186\n",
      "Epoch 7/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.2778 - acc: 0.920 - ETA: 0s - loss: 0.2727 - acc: 0.903 - ETA: 0s - loss: 0.2611 - acc: 0.908 - ETA: 0s - loss: 0.2462 - acc: 0.916 - ETA: 0s - loss: 0.2308 - acc: 0.917 - ETA: 0s - loss: 0.2423 - acc: 0.912 - ETA: 0s - loss: 0.2386 - acc: 0.913 - ETA: 0s - loss: 0.2327 - acc: 0.915 - ETA: 0s - loss: 0.2264 - acc: 0.919 - ETA: 0s - loss: 0.2244 - acc: 0.919 - ETA: 0s - loss: 0.2276 - acc: 0.920 - ETA: 0s - loss: 0.2231 - acc: 0.921 - ETA: 0s - loss: 0.2211 - acc: 0.920 - ETA: 0s - loss: 0.2153 - acc: 0.921 - 1s 310us/step - loss: 0.2152 - acc: 0.9219 - val_loss: 0.2008 - val_acc: 0.9326\n",
      "Epoch 8/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.2054 - acc: 0.930 - ETA: 0s - loss: 0.1746 - acc: 0.937 - ETA: 0s - loss: 0.2302 - acc: 0.925 - ETA: 0s - loss: 0.1935 - acc: 0.940 - ETA: 0s - loss: 0.2008 - acc: 0.939 - ETA: 0s - loss: 0.1927 - acc: 0.939 - ETA: 0s - loss: 0.1908 - acc: 0.938 - ETA: 0s - loss: 0.1931 - acc: 0.935 - ETA: 0s - loss: 0.1913 - acc: 0.935 - ETA: 0s - loss: 0.1849 - acc: 0.937 - ETA: 0s - loss: 0.1850 - acc: 0.938 - 1s 294us/step - loss: 0.1882 - acc: 0.9367 - val_loss: 0.6513 - val_acc: 0.7991\n",
      "Epoch 9/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.4974 - acc: 0.860 - ETA: 0s - loss: 0.3108 - acc: 0.907 - ETA: 0s - loss: 0.2416 - acc: 0.930 - ETA: 0s - loss: 0.2324 - acc: 0.924 - ETA: 0s - loss: 0.2130 - acc: 0.932 - ETA: 0s - loss: 0.1941 - acc: 0.937 - ETA: 0s - loss: 0.1844 - acc: 0.939 - ETA: 0s - loss: 0.1837 - acc: 0.939 - ETA: 0s - loss: 0.1837 - acc: 0.941 - ETA: 0s - loss: 0.1785 - acc: 0.944 - ETA: 0s - loss: 0.1734 - acc: 0.945 - ETA: 0s - loss: 0.1690 - acc: 0.946 - ETA: 0s - loss: 0.1680 - acc: 0.946 - 1s 297us/step - loss: 0.1685 - acc: 0.9457 - val_loss: 0.2991 - val_acc: 0.9003\n",
      "Epoch 10/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.2300 - acc: 0.930 - ETA: 0s - loss: 0.1913 - acc: 0.933 - ETA: 0s - loss: 0.1736 - acc: 0.940 - ETA: 0s - loss: 0.1626 - acc: 0.940 - ETA: 0s - loss: 0.1591 - acc: 0.945 - ETA: 0s - loss: 0.1522 - acc: 0.947 - ETA: 0s - loss: 0.1427 - acc: 0.950 - ETA: 0s - loss: 0.1465 - acc: 0.951 - ETA: 0s - loss: 0.1433 - acc: 0.953 - ETA: 0s - loss: 0.1428 - acc: 0.953 - ETA: 0s - loss: 0.1412 - acc: 0.953 - ETA: 0s - loss: 0.1395 - acc: 0.953 - ETA: 0s - loss: 0.1346 - acc: 0.954 - ETA: 0s - loss: 0.1346 - acc: 0.954 - 1s 305us/step - loss: 0.1327 - acc: 0.9547 - val_loss: 0.1959 - val_acc: 0.9412\n",
      "Epoch 11/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.1231 - acc: 0.940 - ETA: 0s - loss: 0.0920 - acc: 0.965 - ETA: 0s - loss: 0.1057 - acc: 0.960 - ETA: 0s - loss: 0.0956 - acc: 0.966 - ETA: 0s - loss: 0.0999 - acc: 0.965 - ETA: 0s - loss: 0.0990 - acc: 0.966 - ETA: 0s - loss: 0.1008 - acc: 0.965 - ETA: 0s - loss: 0.1015 - acc: 0.963 - ETA: 0s - loss: 0.1053 - acc: 0.962 - ETA: 0s - loss: 0.1041 - acc: 0.961 - ETA: 0s - loss: 0.1098 - acc: 0.960 - ETA: 0s - loss: 0.1110 - acc: 0.960 - ETA: 0s - loss: 0.1128 - acc: 0.959 - 1s 327us/step - loss: 0.1136 - acc: 0.9589 - val_loss: 0.2022 - val_acc: 0.9326\n",
      "Epoch 12/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.1759 - acc: 0.950 - ETA: 0s - loss: 0.1086 - acc: 0.953 - ETA: 0s - loss: 0.1041 - acc: 0.958 - ETA: 0s - loss: 0.1115 - acc: 0.956 - ETA: 0s - loss: 0.1043 - acc: 0.960 - ETA: 0s - loss: 0.1002 - acc: 0.962 - ETA: 0s - loss: 0.0946 - acc: 0.966 - ETA: 0s - loss: 0.0919 - acc: 0.968 - ETA: 0s - loss: 0.0888 - acc: 0.968 - ETA: 0s - loss: 0.0873 - acc: 0.970 - ETA: 0s - loss: 0.0903 - acc: 0.968 - ETA: 0s - loss: 0.0899 - acc: 0.967 - ETA: 0s - loss: 0.0878 - acc: 0.968 - ETA: 0s - loss: 0.0888 - acc: 0.968 - ETA: 0s - loss: 0.0868 - acc: 0.969 - ETA: 0s - loss: 0.0847 - acc: 0.969 - 1s 369us/step - loss: 0.0851 - acc: 0.9695 - val_loss: 0.2000 - val_acc: 0.9369\n",
      "Epoch 13/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.0793 - acc: 0.970 - ETA: 0s - loss: 0.0797 - acc: 0.975 - ETA: 0s - loss: 0.0805 - acc: 0.972 - ETA: 0s - loss: 0.0791 - acc: 0.972 - ETA: 0s - loss: 0.0762 - acc: 0.973 - ETA: 0s - loss: 0.0753 - acc: 0.972 - ETA: 0s - loss: 0.0792 - acc: 0.968 - ETA: 0s - loss: 0.0723 - acc: 0.972 - ETA: 0s - loss: 0.0747 - acc: 0.971 - ETA: 0s - loss: 0.0774 - acc: 0.970 - ETA: 0s - loss: 0.0831 - acc: 0.969 - ETA: 0s - loss: 0.0805 - acc: 0.971 - ETA: 0s - loss: 0.0859 - acc: 0.969 - 1s 308us/step - loss: 0.0846 - acc: 0.9698 - val_loss: 0.2441 - val_acc: 0.9364\n",
      "Epoch 14/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.1386 - acc: 0.950 - ETA: 0s - loss: 0.0912 - acc: 0.966 - ETA: 0s - loss: 0.0813 - acc: 0.972 - ETA: 0s - loss: 0.0798 - acc: 0.968 - ETA: 0s - loss: 0.0752 - acc: 0.970 - ETA: 0s - loss: 0.0750 - acc: 0.970 - ETA: 0s - loss: 0.0711 - acc: 0.973 - ETA: 0s - loss: 0.0848 - acc: 0.968 - ETA: 0s - loss: 0.0839 - acc: 0.968 - ETA: 0s - loss: 0.0771 - acc: 0.970 - ETA: 0s - loss: 0.0742 - acc: 0.971 - ETA: 0s - loss: 0.0738 - acc: 0.972 - ETA: 0s - loss: 0.0737 - acc: 0.972 - 1s 309us/step - loss: 0.0747 - acc: 0.9724 - val_loss: 0.2524 - val_acc: 0.9196\n",
      "Epoch 15/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.0960 - acc: 0.980 - ETA: 0s - loss: 0.0751 - acc: 0.975 - ETA: 0s - loss: 0.0638 - acc: 0.981 - ETA: 0s - loss: 0.0569 - acc: 0.983 - ETA: 0s - loss: 0.0634 - acc: 0.980 - ETA: 0s - loss: 0.0694 - acc: 0.978 - ETA: 0s - loss: 0.0705 - acc: 0.977 - ETA: 0s - loss: 0.0686 - acc: 0.979 - ETA: 0s - loss: 0.0681 - acc: 0.979 - ETA: 0s - loss: 0.0631 - acc: 0.981 - ETA: 0s - loss: 0.0669 - acc: 0.979 - ETA: 0s - loss: 0.0641 - acc: 0.980 - ETA: 0s - loss: 0.0620 - acc: 0.981 - 1s 318us/step - loss: 0.0618 - acc: 0.9814 - val_loss: 0.1763 - val_acc: 0.9485\n",
      "Epoch 16/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.0483 - acc: 0.980 - ETA: 0s - loss: 0.0366 - acc: 0.985 - ETA: 0s - loss: 0.0388 - acc: 0.985 - ETA: 0s - loss: 0.0352 - acc: 0.987 - ETA: 0s - loss: 0.0460 - acc: 0.983 - ETA: 0s - loss: 0.0440 - acc: 0.984 - ETA: 0s - loss: 0.0412 - acc: 0.986 - ETA: 0s - loss: 0.0398 - acc: 0.987 - ETA: 0s - loss: 0.0398 - acc: 0.987 - ETA: 0s - loss: 0.0423 - acc: 0.985 - ETA: 0s - loss: 0.0426 - acc: 0.984 - ETA: 0s - loss: 0.0433 - acc: 0.984 - 1s 298us/step - loss: 0.0424 - acc: 0.9846 - val_loss: 0.3096 - val_acc: 0.9302\n",
      "Epoch 17/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.0269 - acc: 0.990 - ETA: 0s - loss: 0.0447 - acc: 0.985 - ETA: 0s - loss: 0.0383 - acc: 0.988 - ETA: 0s - loss: 0.0425 - acc: 0.986 - ETA: 0s - loss: 0.0415 - acc: 0.987 - ETA: 0s - loss: 0.0400 - acc: 0.987 - ETA: 0s - loss: 0.0367 - acc: 0.988 - ETA: 0s - loss: 0.0341 - acc: 0.990 - ETA: 0s - loss: 0.0476 - acc: 0.985 - ETA: 0s - loss: 0.0465 - acc: 0.985 - ETA: 0s - loss: 0.0497 - acc: 0.983 - ETA: 0s - loss: 0.0501 - acc: 0.982 - 1s 295us/step - loss: 0.0500 - acc: 0.9826 - val_loss: 0.2069 - val_acc: 0.9499\n",
      "Epoch 18/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.0137 - acc: 1.000 - ETA: 0s - loss: 0.0165 - acc: 1.000 - ETA: 0s - loss: 0.0225 - acc: 0.995 - ETA: 0s - loss: 0.0208 - acc: 0.996 - ETA: 0s - loss: 0.0211 - acc: 0.995 - ETA: 0s - loss: 0.0325 - acc: 0.993 - ETA: 0s - loss: 0.0336 - acc: 0.992 - ETA: 0s - loss: 0.0404 - acc: 0.990 - ETA: 0s - loss: 0.0398 - acc: 0.989 - ETA: 0s - loss: 0.0400 - acc: 0.988 - ETA: 0s - loss: 0.0405 - acc: 0.987 - ETA: 0s - loss: 0.0395 - acc: 0.988 - ETA: 0s - loss: 0.0407 - acc: 0.987 - ETA: 0s - loss: 0.0403 - acc: 0.987 - 1s 306us/step - loss: 0.0407 - acc: 0.9871 - val_loss: 0.5448 - val_acc: 0.8748\n",
      "Epoch 19/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.1938 - acc: 0.950 - ETA: 0s - loss: 0.0900 - acc: 0.972 - ETA: 0s - loss: 0.0781 - acc: 0.974 - ETA: 0s - loss: 0.0738 - acc: 0.976 - ETA: 0s - loss: 0.0685 - acc: 0.977 - ETA: 0s - loss: 0.0676 - acc: 0.977 - ETA: 0s - loss: 0.0628 - acc: 0.978 - ETA: 0s - loss: 0.0619 - acc: 0.978 - ETA: 0s - loss: 0.0611 - acc: 0.979 - ETA: 0s - loss: 0.0590 - acc: 0.979 - ETA: 0s - loss: 0.0574 - acc: 0.980 - ETA: 0s - loss: 0.0547 - acc: 0.982 - ETA: 0s - loss: 0.0541 - acc: 0.981 - 1s 301us/step - loss: 0.0541 - acc: 0.9817 - val_loss: 0.2058 - val_acc: 0.9470\n",
      "Epoch 20/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.0164 - acc: 1.000 - ETA: 0s - loss: 0.0301 - acc: 0.990 - ETA: 0s - loss: 0.0302 - acc: 0.988 - ETA: 0s - loss: 0.0259 - acc: 0.991 - ETA: 0s - loss: 0.0267 - acc: 0.991 - ETA: 0s - loss: 0.0256 - acc: 0.991 - ETA: 0s - loss: 0.0260 - acc: 0.990 - ETA: 0s - loss: 0.0256 - acc: 0.990 - ETA: 0s - loss: 0.0257 - acc: 0.990 - ETA: 0s - loss: 0.0253 - acc: 0.990 - ETA: 0s - loss: 0.0236 - acc: 0.991 - ETA: 0s - loss: 0.0237 - acc: 0.991 - ETA: 0s - loss: 0.0254 - acc: 0.991 - ETA: 0s - loss: 0.0262 - acc: 0.991 - ETA: 0s - loss: 0.0258 - acc: 0.992 - 1s 319us/step - loss: 0.0257 - acc: 0.9923 - val_loss: 0.2344 - val_acc: 0.9465\n",
      "Epoch 21/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.0111 - acc: 1.000 - ETA: 0s - loss: 0.0148 - acc: 0.997 - ETA: 0s - loss: 0.0209 - acc: 0.997 - ETA: 0s - loss: 0.0182 - acc: 0.996 - ETA: 0s - loss: 0.0173 - acc: 0.996 - ETA: 0s - loss: 0.0174 - acc: 0.996 - ETA: 0s - loss: 0.0172 - acc: 0.996 - ETA: 0s - loss: 0.0181 - acc: 0.996 - ETA: 0s - loss: 0.0197 - acc: 0.995 - ETA: 0s - loss: 0.0211 - acc: 0.995 - ETA: 0s - loss: 0.0213 - acc: 0.995 - ETA: 0s - loss: 0.0217 - acc: 0.994 - ETA: 0s - loss: 0.0210 - acc: 0.994 - 1s 303us/step - loss: 0.0209 - acc: 0.9949 - val_loss: 0.2659 - val_acc: 0.9427\n",
      "Epoch 22/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.0540 - acc: 0.990 - ETA: 0s - loss: 0.0203 - acc: 0.997 - ETA: 0s - loss: 0.0217 - acc: 0.995 - ETA: 0s - loss: 0.0185 - acc: 0.996 - ETA: 0s - loss: 0.0238 - acc: 0.994 - ETA: 0s - loss: 0.0236 - acc: 0.993 - ETA: 0s - loss: 0.0251 - acc: 0.992 - ETA: 0s - loss: 0.0239 - acc: 0.993 - ETA: 0s - loss: 0.0230 - acc: 0.993 - ETA: 0s - loss: 0.0235 - acc: 0.993 - ETA: 0s - loss: 0.0260 - acc: 0.992 - ETA: 0s - loss: 0.0249 - acc: 0.993 - ETA: 0s - loss: 0.0238 - acc: 0.993 - ETA: 0s - loss: 0.0276 - acc: 0.992 - 1s 300us/step - loss: 0.0280 - acc: 0.9926 - val_loss: 0.5378 - val_acc: 0.8998\n",
      "Epoch 23/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.2245 - acc: 0.920 - ETA: 0s - loss: 0.1146 - acc: 0.963 - ETA: 0s - loss: 0.0722 - acc: 0.976 - ETA: 0s - loss: 0.0569 - acc: 0.981 - ETA: 0s - loss: 0.0486 - acc: 0.985 - ETA: 0s - loss: 0.0441 - acc: 0.985 - ETA: 0s - loss: 0.0390 - acc: 0.987 - ETA: 0s - loss: 0.0358 - acc: 0.988 - ETA: 0s - loss: 0.0366 - acc: 0.988 - ETA: 0s - loss: 0.0347 - acc: 0.989 - ETA: 0s - loss: 0.0327 - acc: 0.990 - ETA: 0s - loss: 0.0316 - acc: 0.990 - ETA: 0s - loss: 0.0347 - acc: 0.988 - ETA: 0s - loss: 0.0338 - acc: 0.989 - 1s 305us/step - loss: 0.0344 - acc: 0.9891 - val_loss: 0.2369 - val_acc: 0.9436\n",
      "Epoch 24/50\n",
      "3112/3112 [==============================] - ETA: 1s - loss: 0.0130 - acc: 1.000 - ETA: 0s - loss: 0.0229 - acc: 0.992 - ETA: 0s - loss: 0.0196 - acc: 0.994 - ETA: 0s - loss: 0.0165 - acc: 0.995 - ETA: 0s - loss: 0.0146 - acc: 0.996 - ETA: 0s - loss: 0.0194 - acc: 0.993 - ETA: 0s - loss: 0.0286 - acc: 0.990 - ETA: 0s - loss: 0.0269 - acc: 0.991 - ETA: 0s - loss: 0.0273 - acc: 0.991 - ETA: 0s - loss: 0.0251 - acc: 0.992 - ETA: 0s - loss: 0.0249 - acc: 0.991 - ETA: 0s - loss: 0.0232 - acc: 0.992 - ETA: 0s - loss: 0.0221 - acc: 0.992 - ETA: 0s - loss: 0.0213 - acc: 0.993 - 1s 312us/step - loss: 0.0211 - acc: 0.9929 - val_loss: 0.2184 - val_acc: 0.9538\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3112/3112 [==============================] - ETA: 0s - loss: 0.0041 - acc: 1.000 - ETA: 0s - loss: 0.0060 - acc: 0.996 - ETA: 0s - loss: 0.0073 - acc: 0.998 - ETA: 0s - loss: 0.0075 - acc: 0.998 - ETA: 0s - loss: 0.0091 - acc: 0.997 - ETA: 0s - loss: 0.0127 - acc: 0.996 - ETA: 0s - loss: 0.0118 - acc: 0.996 - ETA: 0s - loss: 0.0114 - acc: 0.996 - ETA: 0s - loss: 0.0118 - acc: 0.996 - ETA: 0s - loss: 0.0124 - acc: 0.996 - ETA: 0s - loss: 0.0119 - acc: 0.996 - ETA: 0s - loss: 0.0114 - acc: 0.997 - ETA: 0s - loss: 0.0122 - acc: 0.996 - ETA: 0s - loss: 0.0117 - acc: 0.997 - ETA: 0s - loss: 0.0115 - acc: 0.997 - 1s 311us/step - loss: 0.0116 - acc: 0.9971 - val_loss: 0.3504 - val_acc: 0.9355\n",
      "Epoch 26/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.0059 - acc: 1.000 - ETA: 0s - loss: 0.0057 - acc: 1.000 - ETA: 0s - loss: 0.0096 - acc: 0.998 - ETA: 0s - loss: 0.0104 - acc: 0.997 - ETA: 0s - loss: 0.0110 - acc: 0.996 - ETA: 0s - loss: 0.0128 - acc: 0.996 - ETA: 0s - loss: 0.0116 - acc: 0.996 - ETA: 0s - loss: 0.0104 - acc: 0.997 - ETA: 0s - loss: 0.0118 - acc: 0.996 - ETA: 0s - loss: 0.0113 - acc: 0.997 - ETA: 0s - loss: 0.0150 - acc: 0.996 - ETA: 0s - loss: 0.0159 - acc: 0.995 - ETA: 0s - loss: 0.0181 - acc: 0.995 - ETA: 0s - loss: 0.0180 - acc: 0.995 - 1s 321us/step - loss: 0.0186 - acc: 0.9952 - val_loss: 0.2566 - val_acc: 0.9494\n",
      "Epoch 27/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.0066 - acc: 1.000 - ETA: 0s - loss: 0.0198 - acc: 0.997 - ETA: 0s - loss: 0.0241 - acc: 0.995 - ETA: 0s - loss: 0.0200 - acc: 0.995 - ETA: 0s - loss: 0.0216 - acc: 0.995 - ETA: 0s - loss: 0.0185 - acc: 0.996 - ETA: 0s - loss: 0.0181 - acc: 0.996 - ETA: 0s - loss: 0.0248 - acc: 0.994 - ETA: 0s - loss: 0.0249 - acc: 0.994 - ETA: 0s - loss: 0.0228 - acc: 0.995 - ETA: 0s - loss: 0.0222 - acc: 0.995 - ETA: 0s - loss: 0.0222 - acc: 0.994 - 1s 312us/step - loss: 0.0221 - acc: 0.9949 - val_loss: 0.2284 - val_acc: 0.9470\n",
      "Epoch 28/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.0069 - acc: 1.000 - ETA: 0s - loss: 0.0175 - acc: 0.993 - ETA: 0s - loss: 0.0122 - acc: 0.996 - ETA: 0s - loss: 0.0117 - acc: 0.995 - ETA: 0s - loss: 0.0117 - acc: 0.995 - ETA: 0s - loss: 0.0113 - acc: 0.995 - ETA: 0s - loss: 0.0101 - acc: 0.996 - ETA: 0s - loss: 0.0107 - acc: 0.995 - ETA: 0s - loss: 0.0126 - acc: 0.994 - ETA: 0s - loss: 0.0130 - acc: 0.993 - ETA: 0s - loss: 0.0128 - acc: 0.993 - ETA: 0s - loss: 0.0139 - acc: 0.993 - ETA: 0s - loss: 0.0136 - acc: 0.993 - ETA: 0s - loss: 0.0134 - acc: 0.993 - ETA: 0s - loss: 0.0145 - acc: 0.993 - 1s 318us/step - loss: 0.0151 - acc: 0.9933 - val_loss: 0.2773 - val_acc: 0.9470\n",
      "Epoch 29/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.0065 - acc: 1.000 - ETA: 0s - loss: 0.0100 - acc: 0.997 - ETA: 0s - loss: 0.0097 - acc: 0.996 - ETA: 0s - loss: 0.0107 - acc: 0.996 - ETA: 0s - loss: 0.0148 - acc: 0.995 - ETA: 0s - loss: 0.0134 - acc: 0.995 - ETA: 0s - loss: 0.0136 - acc: 0.995 - ETA: 0s - loss: 0.0126 - acc: 0.996 - ETA: 0s - loss: 0.0118 - acc: 0.996 - ETA: 0s - loss: 0.0142 - acc: 0.995 - ETA: 0s - loss: 0.0139 - acc: 0.995 - ETA: 0s - loss: 0.0133 - acc: 0.996 - ETA: 0s - loss: 0.0135 - acc: 0.995 - ETA: 0s - loss: 0.0149 - acc: 0.995 - ETA: 0s - loss: 0.0146 - acc: 0.995 - 1s 333us/step - loss: 0.0145 - acc: 0.9952 - val_loss: 0.2164 - val_acc: 0.9513\n",
      "Epoch 30/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.0056 - acc: 1.000 - ETA: 0s - loss: 0.0129 - acc: 0.995 - ETA: 0s - loss: 0.0139 - acc: 0.993 - ETA: 0s - loss: 0.0113 - acc: 0.995 - ETA: 0s - loss: 0.0104 - acc: 0.996 - ETA: 0s - loss: 0.0098 - acc: 0.996 - ETA: 0s - loss: 0.0087 - acc: 0.996 - ETA: 0s - loss: 0.0073 - acc: 0.997 - ETA: 0s - loss: 0.0089 - acc: 0.996 - ETA: 0s - loss: 0.0087 - acc: 0.996 - ETA: 0s - loss: 0.0081 - acc: 0.996 - ETA: 0s - loss: 0.0077 - acc: 0.997 - ETA: 0s - loss: 0.0070 - acc: 0.997 - ETA: 0s - loss: 0.0066 - acc: 0.997 - 1s 337us/step - loss: 0.0064 - acc: 0.9978 - val_loss: 0.2437 - val_acc: 0.9562\n",
      "Epoch 31/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 1.9534e-04 - acc: 1.000 - ETA: 0s - loss: 0.0020 - acc: 1.0000    - ETA: 0s - loss: 0.0030 - acc: 1.000 - ETA: 0s - loss: 0.0026 - acc: 1.000 - ETA: 0s - loss: 0.0036 - acc: 1.000 - ETA: 0s - loss: 0.0089 - acc: 0.998 - ETA: 0s - loss: 0.0130 - acc: 0.997 - ETA: 0s - loss: 0.0130 - acc: 0.996 - ETA: 0s - loss: 0.0185 - acc: 0.994 - ETA: 0s - loss: 0.0169 - acc: 0.995 - ETA: 0s - loss: 0.0188 - acc: 0.994 - ETA: 0s - loss: 0.0182 - acc: 0.994 - ETA: 0s - loss: 0.0176 - acc: 0.994 - 1s 297us/step - loss: 0.0175 - acc: 0.9945 - val_loss: 0.2708 - val_acc: 0.9485\n",
      "Epoch 32/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.0048 - acc: 1.000 - ETA: 0s - loss: 0.0266 - acc: 0.990 - ETA: 0s - loss: 0.0286 - acc: 0.991 - ETA: 0s - loss: 0.0260 - acc: 0.992 - ETA: 0s - loss: 0.0255 - acc: 0.992 - ETA: 0s - loss: 0.0224 - acc: 0.993 - ETA: 0s - loss: 0.0234 - acc: 0.992 - ETA: 0s - loss: 0.0201 - acc: 0.994 - ETA: 0s - loss: 0.0198 - acc: 0.994 - ETA: 0s - loss: 0.0187 - acc: 0.994 - ETA: 0s - loss: 0.0166 - acc: 0.995 - ETA: 0s - loss: 0.0191 - acc: 0.994 - ETA: 0s - loss: 0.0180 - acc: 0.995 - 1s 296us/step - loss: 0.0204 - acc: 0.9945 - val_loss: 0.2856 - val_acc: 0.9451\n",
      "Epoch 33/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.0237 - acc: 0.990 - ETA: 0s - loss: 0.0114 - acc: 0.995 - ETA: 0s - loss: 0.0194 - acc: 0.995 - ETA: 0s - loss: 0.0184 - acc: 0.994 - ETA: 0s - loss: 0.0192 - acc: 0.995 - ETA: 0s - loss: 0.0221 - acc: 0.993 - ETA: 0s - loss: 0.0234 - acc: 0.992 - ETA: 0s - loss: 0.0213 - acc: 0.993 - ETA: 0s - loss: 0.0196 - acc: 0.994 - ETA: 0s - loss: 0.0191 - acc: 0.994 - ETA: 0s - loss: 0.0195 - acc: 0.993 - ETA: 0s - loss: 0.0182 - acc: 0.994 - 1s 298us/step - loss: 0.0177 - acc: 0.9945 - val_loss: 0.2354 - val_acc: 0.9513\n",
      "Epoch 34/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.0069 - acc: 1.000 - ETA: 0s - loss: 0.0113 - acc: 0.995 - ETA: 0s - loss: 0.0197 - acc: 0.995 - ETA: 0s - loss: 0.0339 - acc: 0.991 - ETA: 0s - loss: 0.0287 - acc: 0.991 - ETA: 0s - loss: 0.0258 - acc: 0.992 - ETA: 0s - loss: 0.0270 - acc: 0.991 - ETA: 0s - loss: 0.0264 - acc: 0.991 - ETA: 0s - loss: 0.0239 - acc: 0.992 - ETA: 0s - loss: 0.0260 - acc: 0.991 - ETA: 0s - loss: 0.0275 - acc: 0.990 - ETA: 0s - loss: 0.0256 - acc: 0.991 - ETA: 0s - loss: 0.0241 - acc: 0.991 - 1s 302us/step - loss: 0.0240 - acc: 0.9920 - val_loss: 0.2512 - val_acc: 0.9470\n",
      "Epoch 35/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.0067 - acc: 1.000 - ETA: 0s - loss: 0.0088 - acc: 0.996 - ETA: 0s - loss: 0.0113 - acc: 0.996 - ETA: 0s - loss: 0.0096 - acc: 0.997 - ETA: 0s - loss: 0.0133 - acc: 0.995 - ETA: 0s - loss: 0.0169 - acc: 0.994 - ETA: 0s - loss: 0.0146 - acc: 0.995 - ETA: 0s - loss: 0.0137 - acc: 0.996 - ETA: 0s - loss: 0.0128 - acc: 0.996 - ETA: 0s - loss: 0.0121 - acc: 0.996 - ETA: 0s - loss: 0.0119 - acc: 0.996 - ETA: 0s - loss: 0.0123 - acc: 0.996 - ETA: 0s - loss: 0.0130 - acc: 0.996 - 1s 300us/step - loss: 0.0127 - acc: 0.9965 - val_loss: 0.2771 - val_acc: 0.9528\n",
      "Epoch 36/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.0109 - acc: 1.000 - ETA: 0s - loss: 0.0036 - acc: 1.000 - ETA: 0s - loss: 0.0071 - acc: 0.996 - ETA: 0s - loss: 0.0094 - acc: 0.995 - ETA: 0s - loss: 0.0075 - acc: 0.996 - ETA: 0s - loss: 0.0067 - acc: 0.997 - ETA: 0s - loss: 0.0061 - acc: 0.997 - ETA: 0s - loss: 0.0065 - acc: 0.997 - ETA: 0s - loss: 0.0064 - acc: 0.997 - ETA: 0s - loss: 0.0059 - acc: 0.997 - ETA: 0s - loss: 0.0056 - acc: 0.997 - ETA: 0s - loss: 0.0063 - acc: 0.997 - ETA: 0s - loss: 0.0059 - acc: 0.997 - 1s 298us/step - loss: 0.0059 - acc: 0.9974 - val_loss: 0.2742 - val_acc: 0.9513\n",
      "Epoch 37/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.0128 - acc: 0.990 - ETA: 0s - loss: 0.0084 - acc: 0.995 - ETA: 0s - loss: 0.0081 - acc: 0.995 - ETA: 0s - loss: 0.0074 - acc: 0.996 - ETA: 0s - loss: 0.0066 - acc: 0.997 - ETA: 0s - loss: 0.0061 - acc: 0.997 - ETA: 0s - loss: 0.0062 - acc: 0.997 - ETA: 0s - loss: 0.0081 - acc: 0.997 - ETA: 0s - loss: 0.0074 - acc: 0.997 - ETA: 0s - loss: 0.0075 - acc: 0.997 - ETA: 0s - loss: 0.0079 - acc: 0.996 - ETA: 0s - loss: 0.0077 - acc: 0.996 - ETA: 0s - loss: 0.0074 - acc: 0.997 - 1s 299us/step - loss: 0.0074 - acc: 0.9971 - val_loss: 0.2634 - val_acc: 0.9528\n",
      "Epoch 38/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 6.5522e-04 - acc: 1.000 - ETA: 0s - loss: 0.0058 - acc: 1.0000    - ETA: 0s - loss: 0.0074 - acc: 0.998 - ETA: 0s - loss: 0.0060 - acc: 0.998 - ETA: 0s - loss: 0.0086 - acc: 0.997 - ETA: 0s - loss: 0.0111 - acc: 0.995 - ETA: 0s - loss: 0.0137 - acc: 0.995 - ETA: 0s - loss: 0.0159 - acc: 0.994 - ETA: 0s - loss: 0.0146 - acc: 0.995 - ETA: 0s - loss: 0.0136 - acc: 0.995 - ETA: 0s - loss: 0.0121 - acc: 0.996 - ETA: 0s - loss: 0.0115 - acc: 0.996 - ETA: 0s - loss: 0.0121 - acc: 0.996 - 1s 313us/step - loss: 0.0124 - acc: 0.9961 - val_loss: 0.3488 - val_acc: 0.9417\n",
      "Epoch 39/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.0010 - acc: 1.000 - ETA: 0s - loss: 0.0033 - acc: 1.000 - ETA: 0s - loss: 0.0043 - acc: 1.000 - ETA: 0s - loss: 0.0034 - acc: 1.000 - ETA: 0s - loss: 0.0032 - acc: 1.000 - ETA: 0s - loss: 0.0058 - acc: 0.998 - ETA: 0s - loss: 0.0105 - acc: 0.996 - ETA: 0s - loss: 0.0094 - acc: 0.997 - ETA: 0s - loss: 0.0107 - acc: 0.996 - ETA: 0s - loss: 0.0099 - acc: 0.996 - ETA: 0s - loss: 0.0110 - acc: 0.996 - ETA: 0s - loss: 0.0104 - acc: 0.996 - ETA: 0s - loss: 0.0100 - acc: 0.996 - ETA: 0s - loss: 0.0100 - acc: 0.996 - ETA: 0s - loss: 0.0097 - acc: 0.996 - 1s 335us/step - loss: 0.0097 - acc: 0.9968 - val_loss: 0.3119 - val_acc: 0.9461\n",
      "Epoch 40/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 9.2679e-04 - acc: 1.000 - ETA: 0s - loss: 0.0017 - acc: 1.0000    - ETA: 0s - loss: 0.0021 - acc: 1.000 - ETA: 0s - loss: 0.0109 - acc: 0.998 - ETA: 0s - loss: 0.0162 - acc: 0.995 - ETA: 0s - loss: 0.0145 - acc: 0.996 - ETA: 0s - loss: 0.0136 - acc: 0.996 - ETA: 0s - loss: 0.0114 - acc: 0.996 - ETA: 0s - loss: 0.0102 - acc: 0.997 - ETA: 0s - loss: 0.0135 - acc: 0.997 - ETA: 0s - loss: 0.0143 - acc: 0.996 - ETA: 0s - loss: 0.0133 - acc: 0.996 - ETA: 0s - loss: 0.0134 - acc: 0.996 - ETA: 0s - loss: 0.0127 - acc: 0.996 - 1s 304us/step - loss: 0.0126 - acc: 0.9968 - val_loss: 0.2829 - val_acc: 0.9485\n",
      "Epoch 41/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.0017 - acc: 1.000 - ETA: 0s - loss: 0.0018 - acc: 1.000 - ETA: 0s - loss: 0.0021 - acc: 1.000 - ETA: 0s - loss: 0.0018 - acc: 1.000 - ETA: 0s - loss: 0.0040 - acc: 0.998 - ETA: 0s - loss: 0.0036 - acc: 0.998 - ETA: 0s - loss: 0.0032 - acc: 0.998 - ETA: 0s - loss: 0.0037 - acc: 0.998 - ETA: 0s - loss: 0.0039 - acc: 0.998 - ETA: 0s - loss: 0.0038 - acc: 0.998 - ETA: 0s - loss: 0.0035 - acc: 0.998 - ETA: 0s - loss: 0.0034 - acc: 0.998 - ETA: 0s - loss: 0.0032 - acc: 0.999 - 1s 300us/step - loss: 0.0034 - acc: 0.9990 - val_loss: 0.2956 - val_acc: 0.9523\n",
      "Epoch 42/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 8.9878e-04 - acc: 1.000 - ETA: 0s - loss: 0.0017 - acc: 1.0000    - ETA: 0s - loss: 0.0019 - acc: 1.000 - ETA: 0s - loss: 0.0016 - acc: 1.000 - ETA: 0s - loss: 0.0048 - acc: 0.999 - ETA: 0s - loss: 0.0045 - acc: 0.999 - ETA: 0s - loss: 0.0082 - acc: 0.998 - ETA: 0s - loss: 0.0077 - acc: 0.998 - ETA: 0s - loss: 0.0131 - acc: 0.996 - ETA: 0s - loss: 0.0134 - acc: 0.995 - ETA: 0s - loss: 0.0160 - acc: 0.995 - ETA: 0s - loss: 0.0151 - acc: 0.996 - ETA: 0s - loss: 0.0140 - acc: 0.996 - 1s 298us/step - loss: 0.0139 - acc: 0.9965 - val_loss: 0.2769 - val_acc: 0.9552\n",
      "Epoch 43/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.0043 - acc: 1.000 - ETA: 0s - loss: 0.0070 - acc: 0.997 - ETA: 0s - loss: 0.0064 - acc: 0.998 - ETA: 0s - loss: 0.0115 - acc: 0.996 - ETA: 0s - loss: 0.0136 - acc: 0.994 - ETA: 0s - loss: 0.0111 - acc: 0.995 - ETA: 0s - loss: 0.0106 - acc: 0.995 - ETA: 0s - loss: 0.0103 - acc: 0.995 - ETA: 0s - loss: 0.0092 - acc: 0.996 - ETA: 0s - loss: 0.0089 - acc: 0.996 - ETA: 0s - loss: 0.0107 - acc: 0.995 - ETA: 0s - loss: 0.0107 - acc: 0.995 - ETA: 0s - loss: 0.0115 - acc: 0.995 - 1s 298us/step - loss: 0.0115 - acc: 0.9955 - val_loss: 0.2900 - val_acc: 0.9499\n",
      "Epoch 44/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.0018 - acc: 1.000 - ETA: 0s - loss: 0.0079 - acc: 0.995 - ETA: 0s - loss: 0.0062 - acc: 0.995 - ETA: 0s - loss: 0.0106 - acc: 0.993 - ETA: 0s - loss: 0.0138 - acc: 0.992 - ETA: 0s - loss: 0.0121 - acc: 0.993 - ETA: 0s - loss: 0.0140 - acc: 0.993 - ETA: 0s - loss: 0.0191 - acc: 0.992 - ETA: 0s - loss: 0.0168 - acc: 0.993 - ETA: 0s - loss: 0.0154 - acc: 0.993 - ETA: 0s - loss: 0.0145 - acc: 0.994 - ETA: 0s - loss: 0.0133 - acc: 0.995 - ETA: 0s - loss: 0.0125 - acc: 0.995 - 1s 296us/step - loss: 0.0121 - acc: 0.9955 - val_loss: 0.3056 - val_acc: 0.9509\n",
      "Epoch 45/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.0052 - acc: 1.000 - ETA: 0s - loss: 0.0019 - acc: 1.000 - ETA: 0s - loss: 0.0032 - acc: 0.998 - ETA: 0s - loss: 0.0025 - acc: 0.998 - ETA: 0s - loss: 0.0023 - acc: 0.999 - ETA: 0s - loss: 0.0043 - acc: 0.998 - ETA: 0s - loss: 0.0040 - acc: 0.998 - ETA: 0s - loss: 0.0061 - acc: 0.997 - ETA: 0s - loss: 0.0066 - acc: 0.997 - ETA: 0s - loss: 0.0068 - acc: 0.996 - ETA: 0s - loss: 0.0062 - acc: 0.996 - ETA: 0s - loss: 0.0059 - acc: 0.997 - ETA: 0s - loss: 0.0061 - acc: 0.996 - ETA: 0s - loss: 0.0057 - acc: 0.997 - 1s 298us/step - loss: 0.0057 - acc: 0.9971 - val_loss: 0.3091 - val_acc: 0.9562\n",
      "Epoch 46/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.0453 - acc: 0.980 - ETA: 0s - loss: 0.0125 - acc: 0.995 - ETA: 0s - loss: 0.0113 - acc: 0.995 - ETA: 0s - loss: 0.0085 - acc: 0.997 - ETA: 0s - loss: 0.0084 - acc: 0.996 - ETA: 0s - loss: 0.0102 - acc: 0.996 - ETA: 0s - loss: 0.0091 - acc: 0.996 - ETA: 0s - loss: 0.0092 - acc: 0.996 - ETA: 0s - loss: 0.0086 - acc: 0.996 - ETA: 0s - loss: 0.0080 - acc: 0.997 - ETA: 0s - loss: 0.0074 - acc: 0.997 - ETA: 0s - loss: 0.0070 - acc: 0.997 - ETA: 0s - loss: 0.0074 - acc: 0.997 - 1s 302us/step - loss: 0.0073 - acc: 0.9971 - val_loss: 0.2891 - val_acc: 0.9533\n",
      "Epoch 47/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 0.0010 - acc: 1.000 - ETA: 0s - loss: 0.0015 - acc: 1.000 - ETA: 0s - loss: 0.0011 - acc: 1.000 - ETA: 0s - loss: 0.0056 - acc: 0.998 - ETA: 0s - loss: 0.0047 - acc: 0.999 - ETA: 0s - loss: 0.0043 - acc: 0.999 - ETA: 0s - loss: 0.0040 - acc: 0.999 - ETA: 0s - loss: 0.0036 - acc: 0.999 - ETA: 0s - loss: 0.0039 - acc: 0.999 - ETA: 0s - loss: 0.0041 - acc: 0.999 - ETA: 0s - loss: 0.0041 - acc: 0.999 - ETA: 0s - loss: 0.0041 - acc: 0.999 - ETA: 0s - loss: 0.0050 - acc: 0.998 - ETA: 0s - loss: 0.0057 - acc: 0.998 - 1s 302us/step - loss: 0.0056 - acc: 0.9981 - val_loss: 0.2681 - val_acc: 0.9562\n",
      "Epoch 48/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 7.2350e-04 - acc: 1.000 - ETA: 0s - loss: 9.1569e-04 - acc: 1.000 - ETA: 0s - loss: 0.0013 - acc: 1.0000    - ETA: 0s - loss: 0.0013 - acc: 1.000 - ETA: 0s - loss: 0.0013 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0012 - acc: 1.000 - ETA: 0s - loss: 0.0026 - acc: 0.999 - ETA: 0s - loss: 0.0025 - acc: 0.999 - ETA: 0s - loss: 0.0024 - acc: 0.999 - ETA: 0s - loss: 0.0029 - acc: 0.999 - ETA: 0s - loss: 0.0027 - acc: 0.999 - ETA: 0s - loss: 0.0038 - acc: 0.998 - 1s 304us/step - loss: 0.0037 - acc: 0.9987 - val_loss: 0.2930 - val_acc: 0.9513\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3112/3112 [==============================] - ETA: 0s - loss: 3.7052e-04 - acc: 1.000 - ETA: 0s - loss: 0.0015 - acc: 1.0000    - ETA: 0s - loss: 0.0037 - acc: 0.998 - ETA: 0s - loss: 0.0040 - acc: 0.997 - ETA: 0s - loss: 0.0043 - acc: 0.998 - ETA: 0s - loss: 0.0037 - acc: 0.998 - ETA: 0s - loss: 0.0064 - acc: 0.998 - ETA: 0s - loss: 0.0086 - acc: 0.997 - ETA: 0s - loss: 0.0080 - acc: 0.998 - ETA: 0s - loss: 0.0078 - acc: 0.998 - ETA: 0s - loss: 0.0074 - acc: 0.998 - ETA: 0s - loss: 0.0072 - acc: 0.998 - ETA: 0s - loss: 0.0067 - acc: 0.998 - ETA: 0s - loss: 0.0071 - acc: 0.998 - 1s 302us/step - loss: 0.0071 - acc: 0.9984 - val_loss: 0.3339 - val_acc: 0.9566\n",
      "Epoch 50/50\n",
      "3112/3112 [==============================] - ETA: 0s - loss: 4.3097e-04 - acc: 1.000 - ETA: 0s - loss: 6.7926e-04 - acc: 1.000 - ETA: 0s - loss: 8.3539e-04 - acc: 1.000 - ETA: 0s - loss: 0.0065 - acc: 0.9986    - ETA: 0s - loss: 0.0096 - acc: 0.995 - ETA: 0s - loss: 0.0087 - acc: 0.996 - ETA: 0s - loss: 0.0118 - acc: 0.996 - ETA: 0s - loss: 0.0128 - acc: 0.994 - ETA: 0s - loss: 0.0122 - acc: 0.994 - ETA: 0s - loss: 0.0121 - acc: 0.994 - ETA: 0s - loss: 0.0137 - acc: 0.994 - ETA: 0s - loss: 0.0133 - acc: 0.994 - ETA: 0s - loss: 0.0146 - acc: 0.994 - ETA: 0s - loss: 0.0140 - acc: 0.994 - ETA: 0s - loss: 0.0133 - acc: 0.994 - 1s 340us/step - loss: 0.0129 - acc: 0.9949 - val_loss: 0.2877 - val_acc: 0.9562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ffeef21b70>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.fit(X_train, y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
